{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos entreneamiento Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a aplicar el shift para las obtener las columnas mas correlacionadas.\n",
    "\n",
    "- __Datos recibidos:__ obtenidos de notebook __1-datos_entrenamiento_shift.ipynb__\n",
    "- __Responsable:__ Daniel Bustillos\n",
    "- __Contacto:__  juandaniel.bucam@gmail.com\n",
    "\n",
    "__Notas del proyecto__\n",
    "Necesitamos generar un csv con los niveles máximos, mínimo y promedio por día, se perderá la información de la estación, también generaremos el atributo PM10mean y PM25mean que representarán los valores de las últimas 24 horas de los contaminantes.\n",
    "\n",
    "calidad de caire\n",
    "pronostico contaminación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos\n",
    "[X] Aplicar Shift con Correlaciones <br>\n",
    "[X] Sacar minimo promedio y maximo <br>\n",
    "[X] Hacer el mes y el día columnas<br><br>\n",
    "[X] Hacer el rollinng para PM10 y PM25<br><br>\n",
    "\n",
    "juntar<br>\n",
    "[X] juntar archivos de append y rolling <br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge_24 = pd.read_csv('./datos_entrenamiento_10-19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quedémonos sin WSR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge_24 = data_hour_merge_24[['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', \"PM2.5\",'RH', 'SO2', 'TMP',\n",
    "       'WSP', 'dia', 'fecha', 'hora', 'id_station', 'mes',\"PM10mean\",\"PM25mean\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos una lista con todas las estaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arreglemos las fechas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge_24 = data_hour_merge_24[data_hour_merge_24.fecha > \"2016-01-01 23:00:00\"]\n",
    "data_hour_merge_24['dia'] = data_hour_merge_24['dia'].astype(str).astype(float)\n",
    "data_hour_merge_24['mes'] = data_hour_merge_24['mes'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creemos un diccionario con __data_hour_merge_24__ dividido por estación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones = data_hour_merge_24.id_station.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_est = {}\n",
    "for elem in estaciones:\n",
    "    data_est[elem] = data_hour_merge_24[data_hour_merge_24.id_station == elem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leamos el archivo de correlaciones del PM10 mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este archivo se generó en el notebook: __/home/paw/DanielBustillos/contaminación/correlaciones_pau/correlaciones_función_paulina.ipynb__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "O3_corr = pd.read_csv('/home/paw/DanielBustillos/contaminación/correlaciones_pau/PM10_corr.csv')\n",
    "O3_corr = O3_corr.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a quedarnos con las variables con corr>0.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "O3_corr_filtro = O3_corr[(O3_corr.valor>0.4) | (O3_corr.valor>0.4) ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar el shift para cada elemento de la tabla __O3_corr__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shit_corr(df):\n",
    "    for i in range(len(O3_corr_filtro)):\n",
    "        name_column = str( O3_corr_filtro.loc[i,\"contaminante\"] + \"_\" + str( O3_corr_filtro.loc[i,\"horas\"] ) ) \n",
    "        df[name_column] = df[O3_corr_filtro.loc[i,\"contaminante\"]].shift( - int(str(O3_corr_filtro.loc[i,\"horas\"])) ) \n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos esta función para cada DF de cada estación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shift = {}\n",
    "for elem in data_est:\n",
    "    data_shift[elem] = shit_corr(data_est[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = pd.DataFrame(columns = data_est[\"MER\"].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_est:\n",
    "    df_append = df_append.append(data_est[key], ignore_index=True,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupbys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_append.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"id_station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, aplicamos los groupbys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge_24_mean = df_append.groupby(['fecha',\"hora\",\"dia\",\"mes\"]).mean()\n",
    "data_hour_merge_24_mean.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge_24_max = df_append.groupby(['fecha',\"hora\",\"dia\",\"mes\"]).max()\n",
    "data_hour_merge_24_max.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge_24_min = df_append.groupby(['fecha',\"hora\",\"dia\",\"mes\"]).min()\n",
    "data_hour_merge_24_min.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unamos los df's de manera que tengamos en una solo los datos promedio, máximo y minimo por día:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge = pd.merge(data_hour_merge_24_mean, data_hour_merge_24_max, on=['fecha',\"hora\",\"dia\",\"mes\"])\n",
    "data_hour_merge = pd.merge(data_hour_merge, data_hour_merge_24_min, on=['fecha',\"hora\",\"dia\",\"mes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "guardamos el archivo:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_hour_merge.to_csv(\"./datos_gb_PM10.csv\", sep=',', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leamos el archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge = pd.read_csv(\"./datos_gb_PM10.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>dia</th>\n",
       "      <th>mes</th>\n",
       "      <th>CO_x</th>\n",
       "      <th>NO_x</th>\n",
       "      <th>NO2_x</th>\n",
       "      <th>NO2_0_x</th>\n",
       "      <th>NOX_x</th>\n",
       "      <th>O3_x</th>\n",
       "      <th>...</th>\n",
       "      <th>PM25mean_5</th>\n",
       "      <th>PM25mean_6</th>\n",
       "      <th>PM25mean_7</th>\n",
       "      <th>PM25mean_8</th>\n",
       "      <th>PM25mean_9</th>\n",
       "      <th>RH</th>\n",
       "      <th>SO2</th>\n",
       "      <th>TMP</th>\n",
       "      <th>WSP</th>\n",
       "      <th>id_station_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-02 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.416667</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>27.791667</td>\n",
       "      <td>28.708333</td>\n",
       "      <td>29.416667</td>\n",
       "      <td>55.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>HGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.041667</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>HGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-02 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>21.125000</td>\n",
       "      <td>21.041667</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>HGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-02 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.041667</td>\n",
       "      <td>21.125000</td>\n",
       "      <td>21.041667</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>HGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-02 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.041667</td>\n",
       "      <td>21.125000</td>\n",
       "      <td>21.041667</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>HGM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fecha  hora  dia  mes      CO_x       NO_x      NO2_x  \\\n",
       "0  2016-01-02 00:00:00     0  2.0  1.0  0.950000  22.666667  40.000000   \n",
       "1  2016-01-02 01:00:00     1  2.0  1.0  0.500000   3.833333  21.166667   \n",
       "2  2016-01-02 02:00:00     2  2.0  1.0  0.500000   4.166667  20.166667   \n",
       "3  2016-01-02 03:00:00     3  2.0  1.0  0.466667   3.500000  18.166667   \n",
       "4  2016-01-02 04:00:00     4  2.0  1.0  0.500000   2.833333  17.333333   \n",
       "\n",
       "     NO2_0_x      NOX_x      O3_x      ...       PM25mean_5  PM25mean_6  \\\n",
       "0  40.000000  62.666667  2.500000      ...        25.416667   26.666667   \n",
       "1  21.166667  25.166667  8.500000      ...        21.041667   21.250000   \n",
       "2  20.166667  24.333333  7.833333      ...        21.125000   21.041667   \n",
       "3  18.166667  21.333333  8.000000      ...        21.041667   21.125000   \n",
       "4  17.333333  20.333333  6.000000      ...        21.000000   21.041667   \n",
       "\n",
       "   PM25mean_7  PM25mean_8  PM25mean_9    RH  SO2   TMP  WSP  id_station_y  \n",
       "0   27.791667   28.708333   29.416667  55.0  9.0  15.9  1.3           HGM  \n",
       "1   21.166667   21.000000   20.125000  73.0  6.0  12.0  1.4           HGM  \n",
       "2   21.250000   21.166667   21.000000  74.0  4.0  12.1  1.2           HGM  \n",
       "3   21.041667   21.250000   21.166667  73.0  2.0  12.0  1.2           HGM  \n",
       "4   21.125000   21.041667   21.250000  73.0  2.0  11.9  1.1           HGM  \n",
       "\n",
       "[5 rows x 363 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hour_merge.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlacionados con el target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a sacar los atributos más correlacionado con el target, el target es la columna a pronosticar, por simplicidad solo vamos a sacar la correlación con target a las 12 horas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos los target de pronóstico:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos el shift de 1 a 24 horas, ahora hacia adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"PM10mean_y\"\n",
    "for i in range(1, 25):\n",
    "    col_name = str(item+\"_frcst_\"+str(i))\n",
    "    data_hour_merge[col_name] = data_hour_merge[item].shift(i)\n",
    "data_hour_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saquemos la correlación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = data_hour_merge.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los atributos mas correlacionados en una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_mas_correlacionadas_pm10_mean = data_corr[\"PM10mean_y_frcst_24\"][(data_corr[\"PM10mean_y_frcst_24\"] > 0.2) |\n",
    "                                                                           (data_corr[\"PM10mean_y_frcst_24\"] < -0.2)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_mas_correlacionadas_pm10_mean.append(\"TMP\")\n",
    "variables_mas_correlacionadas_pm10_mean.append(\"WSP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardemos estas variables, no pueden cambiarse una vez que los modelos estan entrenados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./variables+correlacionadas/vars_mas_corr_pm10mean.txt\", \"w\") as output:\n",
    "    output.write(str(variables_mas_correlacionadas_pm10_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtremos el DF con las variables mas correlacionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hour_merge = data_hour_merge[variables_mas_correlacionadas_pm10_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadamos los datos de pronostico de las siguientes variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_frcst = [\"TMP\",\"WSP\",\"RH\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in lista_frcst:\n",
    "    for i in range(1, 25):\n",
    "        col_name = str(item+\"_frcst_\"+str(i))\n",
    "        data_hour_merge[col_name] = data_hour_merge[item].shift(i)\n",
    "data_hour_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardemos:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_hour_merge.to_csv(\"./datos_entrenamiento_pm10_mean.csv\",sep=',', encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
