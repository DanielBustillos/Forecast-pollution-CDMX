{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntar y limpiar archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a limpiar y a generar groupbys en los archivos históricos para poder alimentar a los modelos de ML adecuadamente.\n",
    "\n",
    "- __Datos recibidos:__ obtenidos de [el portal de calidad del aire de la CDMX](http://www.aire.cdmx.gob.mx/default.php?opc='aKBhnmI='&opcion=Zg==)\n",
    "- __Responsable:__ Daniel Bustillos\n",
    "- __Contacto:__  juandaniel.bucam@gmail.com\n",
    "\n",
    "__Notas del proyecto__\n",
    "Necesitamos generar un csv con los niveles máximos, mínimo y promedio por día, se perderá la información de la estación, también generaremos el atributo PM10mean y PM25mean que representarán los valores de las últimas 24 horas de los contaminantes.\n",
    "\n",
    "calidad de caire\n",
    "pronostico contaminación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos\n",
    "[X] Leer los 10 archivos de contaminación <br>\n",
    "[X] concatenar los archivos<br>\n",
    "[X] Hacer el mes y el día columnas<br><br>\n",
    "[X] Hacer el rollinng para PM10 y PM25<br><br>\n",
    "[X] identidicar y eliminar Outliers\n",
    "[X] Formatear Fechas\n",
    "juntar<br>\n",
    "[X] juntar archivos de append y rolling <br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leamos los DF generados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los archivos por hora:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos todos los archivos enuna sola lista"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lista = [\"cont_hora2000.csv\" ,\"cont_hora2004.csv\",\"cont_hora2008.csv\", \"cont_hora2012.csv\",\n",
    "         \"cont_hora2016.csv\",\"cont_hora2001.csv\" , \"cont_hora2005.csv\",\"cont_hora2009.csv\",\n",
    "         \"cont_hora2013.csv\", \"cont_hora2017.csv\",\"cont_hora2002.csv\",\"cont_hora2006.csv\", \n",
    "         \"cont_hora2010.csv\", \"cont_hora2014.csv\", \"cont_hora2018.csv\",\"cont_hora2003.csv\",\n",
    "         \"cont_hora2007.csv\", \"cont_hora2011.csv\",\"cont_hora2015.csv\",\"cont_hora2019.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [\"cont_hora2016.csv\", \"cont_hora2017.csv\", \"cont_hora2018.csv\"\n",
    "         ,\"cont_hora2015.csv\",\"cont_hora2019.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los archivos y creamos un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hora = {}\n",
    "for elem in lista:\n",
    "    data_hora[elem[9:13]] = pd.read_csv(str('/home/paw/DanielBustillos/contaminación/datasets/por_hora/'+elem))\n",
    "    data_hora[elem[9:13]] = data_hora[elem[9:13]].iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apendeamos todos los DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = pd.DataFrame(columns=data_hora[\"2019\"].columns.tolist())\n",
    "for key in data_hora:\n",
    "    df_append = df_append.append(data_hora[key], ignore_index=True,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtro fechas\n",
    "\n",
    "Nos quedamos únicamente con los datos del 2010 en adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = df_append[df_append.fecha > \"2016-01-01 23:00:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arreglamos las fechas, vamos a generar columnas con el atributo hora,dia,mes. Además, vamos a hacer que la columna fecha contenga la hora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append['dia'] = df_append['fecha'].astype(str).str[8:10]\n",
    "df_append['mes'] =  df_append['fecha'].astype(str).str[5:7]\n",
    "df_append['fecha'] = df_append['fecha'].astype(str).str[0:10]\n",
    "\n",
    "df_append['fecha']  = pd.to_datetime([''.join([' '.join([df_append.loc[i, 'fecha'], \n",
    "                                                         str(df_append.loc[i, 'hora'])]),':00']) for i in df_append.index])\n",
    "df_append['fecha'] = pd.to_datetime(df_append['fecha'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>PBa</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PMCO</th>\n",
       "      <th>RH</th>\n",
       "      <th>...</th>\n",
       "      <th>TMP</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WSP</th>\n",
       "      <th>dia</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>id_station</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>01</td>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>AJM</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>01</td>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>AJU</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>01</td>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>BJU</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>CAM</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>CCA</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO    NO   NO2   NOX    O3  PBa  PM10  PM2.5  PMCO    RH  ...   TMP  \\\n",
       "552  0.4   0.0  14.0  15.0  40.0  NaN  32.0   13.0  19.0  28.0  ...  15.4   \n",
       "553  NaN   NaN   NaN   NaN   5.0  NaN   NaN   15.0   NaN  86.0  ...   2.6   \n",
       "554  1.4   NaN   NaN   NaN   2.0  NaN  48.0   27.0  21.0  45.0  ...  14.1   \n",
       "555  1.1  19.0  41.0  60.0   1.0  NaN  43.0   20.0  23.0   NaN  ...   NaN   \n",
       "556  0.5   2.0  22.0  25.0  21.0  NaN   NaN   14.0   NaN   NaN  ...   NaN   \n",
       "\n",
       "     UVA  UVB    WDR  WSP  dia               fecha hora id_station mes  \n",
       "552  NaN  NaN  224.0  2.5   01 2016-02-01 01:00:00    1        AJM  02  \n",
       "553  NaN  NaN  210.0  1.7   01 2016-02-01 01:00:00    1        AJU  02  \n",
       "554  NaN  NaN  255.0  1.4   01 2016-02-01 01:00:00    1        BJU  02  \n",
       "555  NaN  NaN    NaN  NaN   01 2016-02-01 01:00:00    1        CAM  02  \n",
       "556  NaN  NaN    NaN  NaN   01 2016-02-01 01:00:00    1        CCA  02  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenemos el DF por fecha y estación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = df_append.sort_values(['id_station','fecha'], ascending=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_append = df_append.drop_duplicates()\n",
    "#df_append = df_append[1::]\n",
    "df_append = df_append.drop([\"PBa\",\"PMCO\",\"UVA\",\"UVB\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a quedarnos con las celdas donde Pm10 y Pm2.5 son no nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = df_append.reset_index(drop=True)#PM25\n",
    "df_append[\"PM2.5\"] = df_append[\"PM2.5\"].astype(float)\n",
    "df_append[\"NO\"] = df_append[\"NO\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos PM10 y PM25:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tenemos valores muy grandes, Jiang (2004) reportó que para valores mayores de 300 puntos, las mediciones no son confiables, vamos a quedarnos con mediciones menores a esta cota:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Jiang, D., Zhang, Y., Hu, X., Zeng, Y., Tan, J., & Shao, D. (2004). Progress in developing an ANN model for air pollution index forecast. Atmospheric Environment, 38(40 SPEC.ISS.), 7055–7064. https://doi.org/10.1016/j.atmosenv.2003.10.066__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No queremos perder fechas, vamos a quedarnos con el valor anterior al outlier:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(df_append)):\n",
    "    if df_append.loc[i,\"PM10\"] > 450:\n",
    "        df_append.loc[i,\"PM10\"] = df_append.loc[i-1,\"PM10\"]\n",
    "    if df_append.loc[i,\"PM2.5\"] > 450:\n",
    "        df_append.loc[i,\"PM2.5\"] = df_append.loc[i-1,\"PM2.5\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"hora\", y=\"PM2.5\", data=df_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Datos por día: mean(), max(), min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos un Df con los datos promedio por hora oara rellenar los nan del DF original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = df_append.sort_values(['fecha','id_station'], ascending=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>RH</th>\n",
       "      <th>SO2</th>\n",
       "      <th>TMP</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WSP</th>\n",
       "      <th>dia</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>id_station</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23978</th>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>02</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>AJM</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51941</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>02</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>AJU</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131383</th>\n",
       "      <td>1.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>CAM</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154797</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>CCA</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181618</th>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>02</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>CHO</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CO    NO   NO2   NOX    O3  PM10  PM2.5    RH   SO2   TMP    WDR  \\\n",
       "23978   0.6   2.0  24.0  26.0  14.0   NaN    NaN  62.0   2.0  14.8  189.0   \n",
       "51941   NaN   NaN   NaN   NaN  16.0   NaN    3.0  92.0   NaN   8.5  195.0   \n",
       "131383  1.1  15.0  40.0  55.0   2.0  53.0   17.0   NaN  19.0   NaN    NaN   \n",
       "154797  0.9   3.0  39.0  42.0  11.0   NaN   19.0   NaN   NaN   NaN    NaN   \n",
       "181618  0.6   NaN   NaN   NaN  27.0  21.0    NaN  65.0   1.0  14.0  149.0   \n",
       "\n",
       "        WSP dia      fecha hora id_station mes  \n",
       "23978   1.9  02 2016-01-02    0        AJM  01  \n",
       "51941   1.3  02 2016-01-02    0        AJU  01  \n",
       "131383  NaN  02 2016-01-02    0        CAM  01  \n",
       "154797  NaN  02 2016-01-02    0        CCA  01  \n",
       "181618  1.0  02 2016-01-02    0        CHO  01  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_24 = df_append.set_index('fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora vamos a sacar el promedio de las ultimas 24 horas por estación para el PM10 y el PM25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_24 = data_24.groupby('id_station')[[\"PM10\",\"PM2.5\"]].rolling(24).mean().dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_24 = data_24.rename(columns={'PM10': 'PM10mean',\"PM2.5\":'PM25mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unir los archivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos los dos DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_day = pd.merge(df_append, data_24, on=[\"fecha\",\"id_station\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_day.to_csv(str(\"./datos_entrenamiento.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
